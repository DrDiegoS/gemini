import streamlit as st
import requests
import json
import time
import os  # Para acessar vari√°veis de ambiente
from dotenv import load_dotenv

# Carrega vari√°veis de ambiente do arquivo .env (se existir)
load_dotenv()

st.set_page_config(page_title="Gemini Chat", page_icon="ü§ñ", layout="wide")  # 'wide' para tela cheia

# ---- Sidebar ----
with st.sidebar:
    st.title("ü§ñ Gemini AI Chat")
    st.markdown("Um chatbot com a API Gemini.")
    st.markdown("---")
    # API Key (usando st.secrets para maior seguran√ßa)
    API_KEY = st.text_input("Chave da API Google Gemini", type="password", value=os.getenv("GOOGLE_API_KEY", ""))  # Pega do .env ou deixa em branco
    if not API_KEY:
        st.warning("Por favor, insira sua chave da API Google Gemini.")
    st.markdown("---")
    st.markdown(
        """
        **Informa√ß√µes:**
        *  Utiliza a API Google Gemini (Generative AI).
        *  [Documenta√ß√£o da API](https://ai.google.dev/)
        *  [Como obter uma chave API](https://makersuite.google.com/app/apikey)
        """
    )

# ---- Main Area ----

# Escolha do modelo
model = st.selectbox("Escolha o modelo:", ["gemini-2.0-flash", "gemini-1.5-pro", "gemini-1.5-flash"])

# Hist√≥rico de conversas (mais visual)
if "history" not in st.session_state:
    st.session_state.history = []

def display_conversation():
    """Exibe o hist√≥rico de conversas em caixas separadas."""
    for i, (q, a) in enumerate(reversed(st.session_state.history)):
        with st.chat_message("user"):
            st.markdown(q)
        with st.chat_message("assistant"):
            st.markdown(a)


# Input Area (na parte inferior para dar a apar√™ncia de chat)
prompt = st.chat_input("Digite sua pergunta:") # Usando st.chat_input

if prompt:
    # Adiciona a pergunta ao hist√≥rico imediatamente
    st.session_state.history.append((prompt, ""))
    display_conversation() # Atualiza a tela para mostrar a pergunta do usu√°rio

    if not API_KEY:
        st.error("Por favor, insira sua chave da API Google Gemini na barra lateral.")
    else:
        with st.spinner("Gerando resposta..."):
            start_time = time.time()
            url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"
            headers = {"Content-Type": "application/json", "X-goog-api-key": API_KEY}
            payload = {"contents": [{"parts": [{"text": prompt}]}]}

            response = requests.post(url, headers=headers, data=json.dumps(payload))
            elapsed = round(time.time() - start_time, 2)

            if response.status_code == 200:
                data = response.json()
                if "candidates" in data:
                    output_text = data["candidates"][0]["content"]["parts"][0]["text"]
                    # Atualiza o hist√≥rico com a resposta do modelo
                    st.session_state.history[-1] = (prompt, output_text) # Substitui o "" pela resposta
                    # Mostra a resposta
                    with st.chat_message("assistant"):
                        st.markdown(output_text)
                    st.success(f"Resposta gerada em {elapsed} segundos.")
                    st.download_button("üì• Baixar resposta", output_text, file_name="resposta.txt")
                else:
                    st.warning("Nenhuma resposta gerada.")
            else:
                st.error(f"Erro {response.status_code}: {response.text}")

# Exibe o hist√≥rico de conversas (ap√≥s a gera√ß√£o da resposta)
display_conversation()
